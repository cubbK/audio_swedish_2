{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d42c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y ffmpeg\n",
    "%pip install pandas datasets[audio] snac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b2f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "df = load_dataset(\"cubbk/audio_swedish_2_dataset_cleaned\", split='train', streaming=True, data_dir=\"8sidor_text_speech_dataset\", data_files=\"jobs_dataset-000011.tar\")\n",
    "\n",
    "for i, dataset_item in enumerate(df):\n",
    "    print(i, dataset_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb09bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "from snac import SNAC\n",
    "import torch\n",
    "\n",
    "model = SNAC.from_pretrained(\"hubertsiuzdak/snac_24khz\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "def tokenise_audio(waveform, sp):\n",
    "#   waveform = torch.from_numpy(waveform).unsqueeze(0)\n",
    "#   waveform = waveform.to(dtype=torch.float32)\n",
    "#   resample_transform = T.Resample(orig_freq=sp, new_freq=24000)\n",
    "#   waveform = resample_transform(waveform)\n",
    "  waveform = torch.from_numpy(waveform).unsqueeze(0).to(dtype=torch.float32)\n",
    "  #generate the codes from snac\n",
    "  with torch.inference_mode():\n",
    "    codes = model.encode(waveform)\n",
    "\n",
    "  all_codes = []\n",
    "  for i in range(codes[0].shape[1]):\n",
    "    all_codes.append(codes[0][0][i].item()+128266)\n",
    "    all_codes.append(codes[1][0][2*i].item()+128266+4096)\n",
    "    all_codes.append(codes[2][0][4*i].item()+128266+(2*4096))\n",
    "    all_codes.append(codes[2][0][(4*i)+1].item()+128266+(3*4096))\n",
    "    all_codes.append(codes[1][0][(2*i)+1].item()+128266+(4*4096))\n",
    "    all_codes.append(codes[2][0][(4*i)+2].item()+128266+(5*4096))\n",
    "    all_codes.append(codes[2][0][(4*i)+3].item()+128266+(6*4096))\n",
    "\n",
    "\n",
    "  return all_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42efcd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "\n",
    "tokeniser_length = 128256\n",
    "start_of_text = 128000\n",
    "end_of_text = 128009\n",
    "\n",
    "start_of_speech = tokeniser_length + 1\n",
    "end_of_speech = tokeniser_length + 2\n",
    "\n",
    "start_of_human = tokeniser_length + 3\n",
    "end_of_human = tokeniser_length + 4\n",
    "\n",
    "start_of_ai = tokeniser_length + 5\n",
    "end_of_ai =  tokeniser_length + 6\n",
    "pad_token = tokeniser_length + 7\n",
    "\n",
    "audio_tokens_start = tokeniser_length + 10\n",
    "\n",
    "tokenizer_name = \"canopylabs/orpheus-3b-0.1-pretrained\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "num_proc = os.cpu_count() - 2\n",
    "\n",
    "for example in ds:\n",
    "    print(example[\"text\"])\n",
    "    print(example[\"codes_list\"])\n",
    "\n",
    "ds = ds.filter(lambda x: x[\"codes_list\"] is not None)\n",
    "ds = ds.filter(lambda x: len(x[\"codes_list\"]) > 0)\n",
    "\n",
    "#@title Create Input Ids\n",
    "def remove_duplicate_frames(example):\n",
    "    vals = example[\"codes_list\"]\n",
    "    if len(vals) % 7 != 0:\n",
    "        raise ValueError(\"Input list length must be divisible by 7\")\n",
    "\n",
    "    result = vals[:7]\n",
    "\n",
    "    removed_frames = 0\n",
    "\n",
    "    for i in range(7, len(vals), 7):\n",
    "        current_first = vals[i]\n",
    "        previous_first = result[-7]\n",
    "\n",
    "        if current_first != previous_first:\n",
    "            result.extend(vals[i:i+7])\n",
    "        else:\n",
    "            removed_frames += 1\n",
    "\n",
    "    example[\"codes_list\"] = result\n",
    "\n",
    "    return example\n",
    "\n",
    "ds = ds.map(remove_duplicate_frames, num_proc=num_proc)\n",
    "\n",
    "tok_info = '''*** HERE you can modify the text prompt\n",
    "i.e. if you wanted a multispeaker model like canopylabs/orpheus-3b-0.1-ft, you can pass:\n",
    "f\"{example[\"source\"]}:  {example[\"text\"]}\", as is passed.\n",
    "'''\n",
    "print(tok_info)\n",
    "\n",
    "def create_input_ids(example):\n",
    "    text_ids = tokenizer.encode(example[\"text\"],  add_special_tokens=True)\n",
    "    text_ids.append(end_of_text)\n",
    "    example[\"text_tokens\"] = text_ids\n",
    "    input_ids = (\n",
    "        [start_of_human]\n",
    "        + example[\"text_tokens\"]\n",
    "        + [end_of_human]\n",
    "        + [start_of_ai]\n",
    "        + [start_of_speech]\n",
    "        + example[\"codes_list\"]\n",
    "        + [end_of_speech]\n",
    "        + [end_of_ai]\n",
    "    )\n",
    "    example[\"input_ids\"] = input_ids\n",
    "    example[\"labels\"] = input_ids\n",
    "    example[\"attention_mask\"] = [1] * len(input_ids)\n",
    "\n",
    "    return example\n",
    "\n",
    "ds = ds.map(create_input_ids, num_proc=num_proc, remove_columns=[\"text\", \"codes_list\"])\n",
    "\n",
    "ds\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
