{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af2045ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.11/dist-packages (1.125.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0.dev20250319+cu128)\n",
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
      "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (4.57.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.28.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.42.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (6.33.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (24.2)\n",
      "Requirement already satisfied: google-cloud-storage<4.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (3.5.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (3.38.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (1.15.0)\n",
      "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.1.2)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.37.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (1.48.0)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.12.4)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (4.15.0)\n",
      "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (0.17.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.1.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.2 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.8.0.dev20250319+cu128)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (1.11.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2024.10.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformers[torch]) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch>=2.2->transformers[torch]) (77.0.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[torch]) (7.0.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.71.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.76.0)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (6.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (4.9.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.5.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.3)\n",
      "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<4.0.0,>=1.32.0->google-cloud-aiplatform) (1.7.1)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (4.9.0)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (15.0.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.2->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.2->transformers[torch]) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-cloud-aiplatform transformers[torch] datasets torchaudio soundfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae6b9405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GPU Memory: 0.00 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c5f8fd343842db92e6e8441b222267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 990 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 07:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.611900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.506600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.103300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.880400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.782500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.530300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.575300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.543200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.423900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.461400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>4.428300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.426600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Allocated=18.46GB, Reserved=62.97GB\n",
      "Step 10: Allocated=18.46GB, Reserved=64.89GB\n",
      "Step 15: Allocated=18.46GB, Reserved=71.31GB\n",
      "Step 20: Allocated=18.46GB, Reserved=71.31GB\n",
      "Step 25: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 30: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 35: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 40: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 45: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 50: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 55: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 60: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 65: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 70: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 75: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 80: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 85: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 90: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 95: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 100: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 105: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 110: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 115: Allocated=18.46GB, Reserved=72.94GB\n",
      "Step 120: Allocated=18.46GB, Reserved=72.94GB\n",
      "Training completed. Model saved to /tmp/model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set BEFORE any torch import\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, Trainer, TrainingArguments, AutoTokenizer, TrainerCallback\n",
    "import numpy as np\n",
    "import torch\n",
    "from google.cloud import storage\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List\n",
    "import gc\n",
    "\n",
    "class MemoryMonitorCallback(TrainerCallback):\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        if state.global_step % 5 == 0:\n",
    "            allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "            reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "            print(f\"Step {state.global_step}: Allocated={allocated:.2f}GB, Reserved={reserved:.2f}GB\")\n",
    "\n",
    "@dataclass\n",
    "class AudioDataCollator:\n",
    "    \"\"\"Custom data collator for audio token sequences with dynamic padding.\"\"\"\n",
    "    tokenizer: Any\n",
    "    pad_token_id: int = 128263\n",
    "    \n",
    "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:\n",
    "        max_length = max(len(f[\"input_ids\"]) for f in features)\n",
    "        \n",
    "        batch_input_ids = []\n",
    "        batch_labels = []\n",
    "        batch_attention_mask = []\n",
    "        \n",
    "        for feature in features:\n",
    "            input_ids = feature[\"input_ids\"]\n",
    "            labels = feature.get(\"labels\", input_ids)\n",
    "            padding_length = max_length - len(input_ids)\n",
    "            \n",
    "            padded_input_ids = input_ids + [self.pad_token_id] * padding_length\n",
    "            batch_input_ids.append(padded_input_ids)\n",
    "            \n",
    "            padded_labels = labels + [-100] * padding_length\n",
    "            batch_labels.append(padded_labels)\n",
    "            \n",
    "            attention_mask = [1] * len(input_ids) + [0] * padding_length\n",
    "            batch_attention_mask.append(attention_mask)\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(batch_input_ids, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(batch_labels, dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(batch_attention_mask, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Clear memory at start\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        gc.collect()\n",
    "        print(f\"Starting GPU Memory: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "    \n",
    "    model_dir = os.environ.get(\"AIP_MODEL_DIR\", \"/tmp/model\")\n",
    "    checkpoint_dir = os.environ.get(\"AIP_CHECKPOINT_DIR\", \"/tmp/checkpoints\")\n",
    "\n",
    "    dsn = \"cubbk/audio_swedish_2_dataset_cleaned\"\n",
    "    model_name = \"canopylabs/orpheus-tts-0.1-pretrained\"\n",
    "\n",
    "    # Optimized settings\n",
    "    epochs = 3\n",
    "    batch_size = 24\n",
    "    pad_token = 128263\n",
    "    save_steps = 1000\n",
    "    learning_rate = 5.0e-5\n",
    "\n",
    "    bf16_supported = torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
    "    dtype = torch.bfloat16 if bf16_supported else torch.float32\n",
    "    if not bf16_supported:\n",
    "        print(\"bfloat16 not supported on this device; using float32.\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.pad_token_id = pad_token\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=dtype,\n",
    "    )\n",
    "    \n",
    "    # Enable gradient checkpointing\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "    raw_ds = load_dataset(dsn, split=\"train\", data_dir=\"8sidor_tokenized\")\n",
    "    raw_ds = raw_ds.select(range(1000))\n",
    "    \n",
    "    # Filter long sequences\n",
    "    raw_ds = raw_ds.filter(lambda x: len(x[\"input_ids\"]) <= 1000)\n",
    "    print(f\"Dataset: {len(raw_ds)} samples\")\n",
    "\n",
    "    split = raw_ds.train_test_split(test_size=0.05, seed=42)\n",
    "    train_ds, eval_ds = split[\"train\"], split[\"test\"]\n",
    "\n",
    "    data_collator = AudioDataCollator(\n",
    "        tokenizer=tokenizer,\n",
    "        pad_token_id=pad_token\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        logging_steps=10,\n",
    "        bf16=bf16_supported,\n",
    "        output_dir=checkpoint_dir,\n",
    "        save_steps=save_steps,\n",
    "        remove_unused_columns=False,\n",
    "        learning_rate=learning_rate,\n",
    "        save_total_limit=1,  # Reduced from 2 to save memory\n",
    "        logging_dir=f\"{checkpoint_dir}/logs\",\n",
    "        warmup_ratio=0.1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_grad_norm=1.0,\n",
    "        dataloader_pin_memory=False,  # Disable pin memory\n",
    "        dataloader_num_workers=0,  # Disable multiprocessing\n",
    "        logging_first_step=True,\n",
    "        logging_nan_inf_filter=False,  # Reduce logging overhead\n",
    "    )\n",
    "\n",
    "    # Use custom trainer with memory management\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[MemoryMonitorCallback()],\n",
    "    )\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    trainer.train()\n",
    "    \n",
    "    trainer.save_model(model_dir)\n",
    "    tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "    print(f\"Training completed. Model saved to {model_dir}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f474d1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.36.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33m⚠️  Warning: 'huggingface-cli upload' is deprecated. Use 'hf upload' instead.\u001b[0m\n",
      "Start hashing 10 files.\n",
      "Finished hashing 10 files.\n",
      "Processing Files (0 / 0)      : |                  |  0.00B /  0.00B            \n",
      "New Data Upload               : |                  |  0.00B /  0.00B            \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "Processing Files (1 / 1)      :   0%|              | 22.8MB / 6.62GB,   ???B/s  \u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:   0%|              | 1.81MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors:   0%|              | 1.81MB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:   0%|              | 1.81MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :   0%|              | 26.5MB / 6.62GB, 9.07MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :   3%|▍             | 3.62MB /  134MB, 9.07MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:   1%|▏             | 66.9MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :   2%|▎             |  156MB / 6.62GB,  222MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  50%|██████▉       |  133MB /  268MB,  222MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:   1%|▏             | 74.8MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :   2%|▎             |  165MB / 6.62GB,  178MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  53%|███████▍      |  142MB /  268MB,  178MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:   3%|▍             |  134MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :   4%|▌             |  290MB / 6.62GB,  267MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  66%|█████████▎    |  267MB /  402MB,  267MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:   3%|▍             |  134MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :   4%|▌             |  291MB / 6.62GB,  223MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  67%|█████████▎    |  268MB /  402MB,  223MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:   4%|▌             |  201MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :   6%|▉             |  423MB / 6.62GB,  286MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  75%|██████████▍   |  401MB /  537MB,  286MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:   4%|▌             |  203MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :   7%|█             |  493MB / 6.62GB,  294MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  88%|████████████▎ |  470MB /  537MB,  294MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:   5%|▋             |  267MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :   8%|█▏            |  558MB / 6.62GB,  297MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  80%|███████████▏  |  535MB /  671MB,  297MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:   5%|▋             |  267MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :   9%|█▎            |  594MB / 6.62GB,  286MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  85%|███████████▉  |  571MB /  671MB,  286MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:   7%|▉             |  334MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  10%|█▍            |  691MB / 6.62GB,  304MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  91%|████████████▋ |  668MB /  738MB,  304MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:   7%|▉             |  335MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  10%|█▍            |  692MB / 6.62GB,  279MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  83%|███████████▋  |  669MB /  805MB,  279MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:   8%|█▏            |  402MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  12%|█▋            |  826MB / 6.62GB,  309MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉|  804MB /  805MB,  309MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:   8%|█▏            |  402MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors:  25%|███▍          |  401MB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:   9%|█▎            |  469MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  14%|██            |  960MB / 6.62GB,  312MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉|  937MB /  939MB,  312MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:   9%|█▎            |  469MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors:  29%|████          |  468MB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  11%|█▌            |  536MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  16%|██▏           | 1.03GB / 6.62GB,  296MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  94%|█████████████ | 1.01GB / 1.07GB,  296MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  11%|█▌            |  536MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  17%|██▎           | 1.09GB / 6.62GB,  298MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  89%|████████████▍ | 1.07GB / 1.21GB,  298MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  12%|█▋            |  603MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  19%|██▌           | 1.23GB / 6.62GB,  317MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 1.20GB / 1.21GB,  317MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  12%|█▋            |  603MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  19%|██▌           | 1.23GB / 6.62GB,  301MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  90%|████████████▌ | 1.21GB / 1.34GB,  301MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  13%|█▉            |  669MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  21%|██▉           | 1.36GB / 6.62GB,  319MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 1.34GB / 1.34GB,  319MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  13%|█▉            |  670MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  21%|██▉           | 1.36GB / 6.62GB,  304MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  91%|████████████▋ | 1.34GB / 1.48GB,  304MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  15%|██            |  737MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  22%|███           | 1.43GB / 6.62GB,  306MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  95%|█████████████▎| 1.41GB / 1.48GB,  306MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  15%|██            |  737MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  23%|███▏          | 1.50GB / 6.62GB,  307MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  92%|████████████▊ | 1.47GB / 1.61GB,  307MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  16%|██▎           |  804MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  25%|███▍          | 1.63GB / 6.62GB,  321MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 1.61GB / 1.61GB,  321MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  16%|██▎           |  804MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  25%|███▍          | 1.63GB / 6.62GB,  309MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  92%|████████████▉ | 1.61GB / 1.74GB,  309MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  17%|██▍           |  864MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  27%|███▋          | 1.76GB / 6.62GB,  321MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▉| 1.73GB / 1.74GB,  321MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  17%|██▍           |  871MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  27%|███▋          | 1.77GB / 6.62GB,  311MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  93%|████████████▉ | 1.74GB / 1.88GB,  311MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  19%|██▋           |  938MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  28%|███▉          | 1.84GB / 6.62GB,  313MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  97%|█████████████▌| 1.81GB / 1.88GB,  313MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  19%|██▋           |  939MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  29%|████          | 1.90GB / 6.62GB,  313MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  93%|█████████████ | 1.88GB / 2.01GB,  313MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  19%|██▋           |  951MB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  29%|████          | 1.91GB / 6.62GB,  305MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  94%|█████████████▏| 1.89GB / 2.01GB,  305MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  20%|██▊           | 1.01GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  31%|████▎         | 2.03GB / 6.62GB,  314MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  94%|█████████████ | 2.01GB / 2.15GB,  314MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  20%|██▊           | 1.01GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors:  62%|████████▋     | 1.00GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  21%|███           | 1.07GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  33%|████▌         | 2.17GB / 6.62GB,  315MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  97%|█████████████▌| 2.14GB / 2.21GB,  315MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  21%|███           | 1.07GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors:  67%|█████████▎    | 1.07GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  23%|███▏          | 1.14GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  35%|████▊         | 2.30GB / 6.62GB,  317MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 2.28GB / 2.28GB,  317MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  23%|███▏          | 1.14GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  35%|████▊         | 2.30GB / 6.62GB,  308MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  94%|█████████████▏| 2.28GB / 2.41GB,  308MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  24%|███▍          | 1.21GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  36%|█████         | 2.41GB / 6.62GB,  314MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 2.38GB / 2.41GB,  314MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  24%|███▍          | 1.21GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  37%|█████▏        | 2.44GB / 6.62GB,  309MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  95%|█████████████▎| 2.41GB / 2.55GB,  309MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  26%|███▌          | 1.27GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  39%|█████▍        | 2.57GB / 6.62GB,  318MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 2.55GB / 2.55GB,  318MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  26%|███▌          | 1.27GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  39%|█████▍        | 2.57GB / 6.62GB,  311MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  95%|█████████████▎| 2.55GB / 2.68GB,  311MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  27%|███▊          | 1.34GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  41%|█████▋        | 2.70GB / 6.62GB,  319MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 2.68GB / 2.68GB,  319MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  27%|███▊          | 1.34GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  41%|█████▋        | 2.70GB / 6.62GB,  312MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  95%|█████████████▎| 2.68GB / 2.82GB,  312MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  28%|███▉          | 1.41GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  43%|█████▉        | 2.84GB / 6.62GB,  320MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 2.81GB / 2.82GB,  320MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  28%|███▉          | 1.41GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors:  87%|████████████▏ | 1.41GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  30%|████▏         | 1.48GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  45%|██████▎       | 2.97GB / 6.62GB,  320MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 2.95GB / 2.95GB,  320MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  30%|████▏         | 1.48GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  45%|██████▎       | 2.97GB / 6.62GB,  314MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  96%|█████████████▍| 2.95GB / 3.08GB,  314MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  31%|████▎         | 1.54GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  47%|██████▌       | 3.10GB / 6.62GB,  320MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 3.07GB / 3.08GB,  320MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  31%|████▎         | 1.54GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  47%|██████▌       | 3.11GB / 6.62GB,  315MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  96%|█████████████▍| 3.08GB / 3.22GB,  315MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  32%|████▌         | 1.61GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  48%|██████▊       | 3.21GB / 6.62GB,  319MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 3.19GB / 3.22GB,  319MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  32%|████▌         | 1.61GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  49%|██████▊       | 3.24GB / 6.62GB,  315MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  98%|█████████████▋| 3.22GB / 3.29GB,  315MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  33%|████▋         | 1.67GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  50%|██████▉       | 3.30GB / 6.62GB,  321MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 3.28GB / 3.29GB,  321MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  34%|████▋         | 1.68GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  50%|██████▉       | 3.31GB / 6.62GB,  322MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  98%|█████████████▋| 3.29GB / 3.35GB,  322MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  34%|████▋         | 1.68GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  35%|████▉         | 1.74GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  51%|███████▏      | 3.37GB / 6.62GB,  315MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 3.35GB / 3.35GB,  315MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  35%|████▉         | 1.74GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  36%|█████         | 1.81GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  52%|███████▎      | 3.44GB / 6.62GB,  309MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 3.42GB / 3.42GB,  309MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  36%|█████         | 1.81GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  38%|█████▎        | 1.88GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  53%|███████▍      | 3.51GB / 6.62GB,  296MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 3.49GB / 3.49GB,  296MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  38%|█████▎        | 1.88GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  39%|█████▍        | 1.94GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  54%|███████▌      | 3.58GB / 6.62GB,  292MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 3.55GB / 3.55GB,  292MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  39%|█████▍        | 1.94GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  40%|█████▋        | 2.01GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  55%|███████▋      | 3.64GB / 6.62GB,  289MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 3.62GB / 3.62GB,  289MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  40%|█████▋        | 2.01GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  55%|███████▋      | 3.64GB / 6.62GB,  276MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  98%|█████████████▋| 3.62GB / 3.69GB,  276MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  42%|█████▊        | 2.08GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  56%|███████▊      | 3.71GB / 6.62GB,  283MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 3.69GB / 3.69GB,  283MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  42%|█████▊        | 2.08GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  56%|███████▊      | 3.71GB / 6.62GB,  270MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  98%|█████████████▋| 3.69GB / 3.76GB,  270MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  43%|██████        | 2.15GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  57%|███████▉      | 3.78GB / 6.62GB,  276MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 3.75GB / 3.76GB,  276MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  43%|██████        | 2.15GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  57%|███████▉      | 3.78GB / 6.62GB,  270MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  98%|█████████████▊| 3.76GB / 3.82GB,  270MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  44%|██████▏       | 2.21GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  58%|████████▏     | 3.85GB / 6.62GB,  270MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 3.82GB / 3.82GB,  270MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  44%|██████▏       | 2.21GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  46%|██████▍       | 2.28GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  59%|████████▎     | 3.91GB / 6.62GB,  263MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 3.89GB / 3.89GB,  263MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  46%|██████▍       | 2.28GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  46%|██████▍       | 2.31GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  59%|████████▎     | 3.94GB / 6.62GB,  253MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 3.92GB / 3.96GB,  253MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  47%|██████▌       | 2.35GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  60%|████████▍     | 3.98GB / 6.62GB,  250MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  98%|█████████████▊| 3.96GB / 4.02GB,  250MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  47%|██████▌       | 2.35GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  48%|██████▊       | 2.41GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  61%|████████▌     | 4.05GB / 6.62GB,  237MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  98%|█████████████▊| 4.02GB / 4.09GB,  237MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  48%|██████▊       | 2.41GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  61%|████████▌     | 4.05GB / 6.62GB,  237MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  98%|█████████████▊| 4.02GB / 4.09GB,  237MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  50%|██████▉       | 2.48GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  62%|████████▋     | 4.11GB / 6.62GB,  231MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 4.09GB / 4.09GB,  231MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  50%|██████▉       | 2.48GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  51%|███████▏      | 2.55GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  63%|████████▊     | 4.18GB / 6.62GB,  230MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 4.16GB / 4.16GB,  230MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  51%|███████▏      | 2.55GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  52%|███████▎      | 2.62GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  64%|████████▉     | 4.25GB / 6.62GB,  229MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 4.22GB / 4.22GB,  229MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  52%|███████▎      | 2.62GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  54%|███████▌      | 2.68GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  65%|█████████     | 4.31GB / 6.62GB,  224MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 4.29GB / 4.29GB,  224MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  54%|███████▌      | 2.68GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  55%|███████▋      | 2.74GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  66%|█████████▏    | 4.37GB / 6.62GB,  216MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 4.35GB / 4.36GB,  216MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  55%|███████▋      | 2.75GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  66%|█████████▎    | 4.38GB / 6.62GB,  204MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  98%|█████████████▊| 4.36GB / 4.43GB,  204MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  55%|███████▋      | 2.75GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  66%|█████████▎    | 4.38GB / 6.62GB,  204MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 4.36GB / 4.43GB,  204MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  56%|███████▉      | 2.82GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  67%|█████████▍    | 4.45GB / 6.62GB,  200MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  98%|█████████████▊| 4.43GB / 4.49GB,  200MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  56%|███████▉      | 2.82GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  58%|████████      | 2.88GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  68%|█████████▌    | 4.51GB / 6.62GB,  191MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 4.49GB / 4.49GB,  191MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  58%|████████      | 2.88GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  68%|█████████▌    | 4.52GB / 6.62GB,  191MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 4.49GB / 4.56GB,  191MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  59%|████████▎     | 2.95GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  69%|█████████▋    | 4.58GB / 6.62GB,  184MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 4.56GB / 4.56GB,  184MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  59%|████████▎     | 2.95GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  60%|████████▍     | 3.02GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  70%|█████████▊    | 4.65GB / 6.62GB,  178MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 4.63GB / 4.63GB,  178MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  60%|████████▍     | 3.02GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  62%|████████▋     | 3.08GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  71%|█████████▉    | 4.72GB / 6.62GB,  171MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 4.69GB / 4.69GB,  171MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  62%|████████▋     | 3.08GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  71%|█████████▉    | 4.72GB / 6.62GB,  171MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 4.69GB / 4.76GB,  171MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  62%|████████▋     | 3.11GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  72%|██████████    | 4.75GB / 6.62GB,  162MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▉| 4.72GB / 4.76GB,  162MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  63%|████████▊     | 3.15GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  72%|██████████    | 4.78GB / 6.62GB,  164MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 4.76GB / 4.83GB,  164MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  63%|████████▉     | 3.17GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  72%|██████████▏   | 4.80GB / 6.62GB,  155MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 4.77GB / 4.83GB,  155MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  64%|█████████     | 3.22GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  73%|██████████▎   | 4.85GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 4.83GB / 4.90GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  64%|█████████     | 3.22GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  66%|█████████▏    | 3.29GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  74%|██████████▍   | 4.92GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 4.90GB / 4.96GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  66%|█████████▏    | 3.29GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  67%|█████████▍    | 3.35GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  75%|██████████▌   | 4.98GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 4.96GB / 4.96GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  67%|█████████▍    | 3.35GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  69%|█████████▌    | 3.42GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  76%|██████████▋   | 5.05GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 5.03GB / 5.03GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  69%|█████████▌    | 3.42GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  70%|█████████▊    | 3.49GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  77%|██████████▊   | 5.12GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 5.10GB / 5.10GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  70%|█████████▊    | 3.49GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  71%|█████████▉    | 3.55GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  78%|██████████▉   | 5.19GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 5.16GB / 5.16GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  71%|█████████▉    | 3.55GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  78%|██████████▉   | 5.19GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 5.16GB / 5.23GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  73%|██████████▏   | 3.62GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  79%|███████████   | 5.25GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 5.23GB / 5.23GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  73%|██████████▏   | 3.62GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  79%|███████████   | 5.25GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 5.23GB / 5.30GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  73%|██████████▏   | 3.65GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  80%|███████████▏  | 5.28GB / 6.62GB,  154MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▉| 5.26GB / 5.30GB,  154MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  74%|██████████▎   | 3.69GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  80%|███████████▏  | 5.32GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 5.30GB / 5.36GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  74%|██████████▍   | 3.70GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  81%|███████████▎  | 5.34GB / 6.62GB,  153MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 5.31GB / 5.36GB,  153MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  75%|██████████▌   | 3.75GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  81%|███████████▍  | 5.39GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 5.36GB / 5.43GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  75%|██████████▌   | 3.75GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  77%|██████████▋   | 3.82GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  82%|███████████▌  | 5.45GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 5.43GB / 5.50GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  77%|██████████▋   | 3.82GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  78%|██████████▉   | 3.89GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  83%|███████████▋  | 5.52GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 5.50GB / 5.50GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  78%|██████████▉   | 3.89GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  83%|███████████▋  | 5.52GB / 6.62GB,  155MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 5.50GB / 5.57GB,  155MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  79%|███████████   | 3.96GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  84%|███████████▊  | 5.59GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 5.57GB / 5.57GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  79%|███████████   | 3.96GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  81%|███████████▎  | 4.02GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  85%|███████████▉  | 5.66GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 5.63GB / 5.63GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  81%|███████████▎  | 4.02GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  82%|███████████▍  | 4.09GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  86%|████████████  | 5.72GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 5.70GB / 5.70GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  82%|███████████▍  | 4.09GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  83%|███████████▋  | 4.16GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  87%|████████████▏ | 5.79GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 5.77GB / 5.77GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  83%|███████████▋  | 4.16GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  85%|███████████▊  | 4.22GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  88%|████████████▍ | 5.86GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 5.83GB / 5.83GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  85%|███████████▊  | 4.22GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  88%|████████████▍ | 5.86GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 5.83GB / 5.90GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  86%|████████████  | 4.28GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  89%|████████████▍ | 5.91GB / 6.62GB,  157MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 5.89GB / 5.90GB,  157MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  86%|████████████  | 4.29GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  89%|████████████▌ | 5.92GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 5.90GB / 5.97GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  86%|████████████  | 4.29GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  87%|████████████▏ | 4.36GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  90%|████████████▋ | 5.99GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 5.97GB / 6.04GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  87%|████████████▏ | 4.36GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  89%|████████████▍ | 4.43GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  91%|████████████▊ | 6.06GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 6.04GB / 6.04GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  89%|████████████▍ | 4.43GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  91%|████████████▊ | 6.06GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 6.04GB / 6.10GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  90%|████████████▌ | 4.49GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  92%|████████████▉ | 6.13GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 6.10GB / 6.10GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  90%|████████████▌ | 4.49GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  91%|████████████▊ | 4.56GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  93%|█████████████ | 6.19GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 6.17GB / 6.17GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  91%|████████████▊ | 4.56GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  93%|████████████▉ | 4.63GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  94%|█████████████▏| 6.26GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 6.24GB / 6.24GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  93%|████████████▉ | 4.63GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  94%|█████████████▏| 4.69GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  95%|█████████████▎| 6.33GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 6.30GB / 6.30GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  94%|█████████████▏| 4.69GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  96%|█████████████▎| 6.33GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 6.30GB / 6.37GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  95%|█████████████▎| 4.73GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  96%|█████████████▍| 6.37GB / 6.62GB,  159MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 6.34GB / 6.37GB,  159MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  95%|█████████████▎| 4.76GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  97%|█████████████▌| 6.39GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 6.37GB / 6.44GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  95%|█████████████▎| 4.76GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  97%|█████████████▌| 4.83GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  98%|█████████████▋| 6.46GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 6.44GB / 6.51GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  97%|█████████████▌| 4.83GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  98%|█████████████▋| 4.90GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  99%|█████████████▊| 6.53GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 6.50GB / 6.51GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  98%|█████████████▋| 4.90GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      :  99%|█████████████▊| 6.53GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               :  99%|█████████████▊| 6.50GB / 6.57GB,  158MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors:  99%|█████████████▉| 4.96GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 3)      : 100%|█████████████▉| 6.59GB / 6.62GB,  158MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 6.57GB / 6.60GB,  158MB/s  \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  /tmp/model/training_args.bin: 100%|█████████████▉| 5.76kB / 5.78kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors: 100%|█████████████▉| 4.99GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 4)      : 100%|█████████████▉| 6.62GB / 6.62GB,  161MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 6.60GB / 6.60GB,  161MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors: 100%|█████████████▉| 4.99GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 4)      : 100%|█████████████▉| 6.62GB / 6.62GB,  154MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 6.60GB / 6.60GB,  154MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors: 100%|█████████████▉| 4.99GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  /tmp/model/training_args.bin: 100%|█████████████▉| 5.76kB / 5.78kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors: 100%|█████████████▉| 4.99GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  /tmp/model/training_args.bin: 100%|█████████████▉| 5.76kB / 5.78kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors: 100%|█████████████▉| 4.99GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (1 / 4)      : 100%|█████████████▉| 6.62GB / 6.62GB,  148MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|█████████████▉| 6.60GB / 6.60GB,  148MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors: 100%|█████████████▉| 4.99GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  /tmp/model/training_args.bin: 100%|█████████████▉| 5.76kB / 5.78kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors: 100%|█████████████▉| 4.99GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  /tmp/model/training_args.bin: 100%|█████████████▉| 5.76kB / 5.78kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors: 100%|█████████████▉| 4.99GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|█████████████▉| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  /tmp/model/training_args.bin: 100%|█████████████▉| 5.76kB / 5.78kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors: 100%|██████████████| 4.99GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|██████████████| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (4 / 4)      : 100%|██████████████| 6.62GB / 6.62GB,  134MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|██████████████| 6.60GB / 6.60GB,  134MB/s  \u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors: 100%|██████████████| 4.99GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|██████████████| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  /tmp/model/training_args.bin: 100%|██████████████| 5.78kB / 5.78kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors: 100%|██████████████| 4.99GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|██████████████| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  /tmp/model/training_args.bin: 100%|██████████████| 5.78kB / 5.78kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors: 100%|██████████████| 4.99GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|██████████████| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  /tmp/model/training_args.bin: 100%|██████████████| 5.78kB / 5.78kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors: 100%|██████████████| 4.99GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|██████████████| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  /tmp/model/training_args.bin: 100%|██████████████| 5.78kB / 5.78kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  ...0001-of-00002.safetensors: 100%|██████████████| 4.99GB / 4.99GB            \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  ...0002-of-00002.safetensors: 100%|██████████████| 1.61GB / 1.61GB            \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing Files (4 / 4)      : 100%|██████████████| 6.62GB / 6.62GB,  124MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "New Data Upload               : 100%|██████████████| 6.60GB / 6.60GB,  124MB/s  \n",
      "  /tmp/model/tokenizer.json   : 100%|██████████████| 22.8MB / 22.8MB            \n",
      "  ...0001-of-00002.safetensors: 100%|██████████████| 4.99GB / 4.99GB            \n",
      "  ...0002-of-00002.safetensors: 100%|██████████████| 1.61GB / 1.61GB            \n",
      "  /tmp/model/training_args.bin: 100%|██████████████| 5.78kB / 5.78kB            \n",
      "https://huggingface.co/cubbk/orpheus-swedish-2/tree/main/.\n"
     ]
    }
   ],
   "source": [
    "%pip install huggingface_hub\n",
    "!huggingface-cli upload cubbk/orpheus-swedish-2 /tmp/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c1030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80cfe301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  5 14:54:48 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  |   00000000:00:05.0 Off |                    0 |\n",
      "| N/A   69C    P0             99W /  300W |   32871MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
